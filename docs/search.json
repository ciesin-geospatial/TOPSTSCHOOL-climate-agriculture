[
  {
    "objectID": "NASA-Acres-Climate-Resilience-Network.html",
    "href": "NASA-Acres-Climate-Resilience-Network.html",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "",
    "text": "A regional view of the past with applications to the present. Python spatial and tabular analysis using multiple variables to look at a single time slice. This code can be a combination of cloud and local based analysis. A purpose for this exercise is to use use public research data for derived conclusions view the impacts climate change has on agriculture a look at what farmers can do and why we need to support them.\nNASA Acres has defined the Essential Agricultural Variables or EAVs. These were designed by NASA Acres to define the capabilities of the top satellite data scientists and practitioners who make up NASA Acres Research, Development, and Extension partners, and the needs of decision-making-collaborators already in our network, to identify an initial set of focus.\n\nCropland and Crop Type Mapping\nCrop and Crop Type Area Estimation\n\nDerived results will be the county level statistics of impacts of harvestable acreage. To achieve this, a basic workflow we can\n\nUse api to call in the CDL dataset to map crop types.\n\nThen\n\nAccess the Sea level rise (elevation dataset) to identify new areas of potential areas that are at risk of future flooding. Clip to county of interest\nCompare the CDL with the SLR mask and with out to identify the NOAA estimated loss of land.\n\nThen using MODIS create a time series for NDVI of the masked crop land, derive insights about trends in NDVI\n\nUse NDVI to create a time series looking backwards in time at areas that have experienced flooding to visualize the moving from productive farms to moderate quality.\n\nThis all together would allow us to make a predictive analysis for Maryland in the future under the projections of sea level rise. Given the current conditions, subtracting the sea level rise inundated areas. Then given the remaining areas, making predictions about the trends of NDVI given the trends in historical areas that are near impacted areas. We cannot say that “sea level rise is driving the decrease” because there are many other factor and decisions that farmers make around how much to plant, how much to harvest, chemicals applied, growing degree days, soil and soil moisture conditions. But this module should provide the ability to make insights about potential causes and impacts.\nThe data story that we have derived is about sea level rise in Maryland and the impact that it has on the production levels with in the state. From this module, we can provide students with the ability to draw from multiple data sources, as well as derive insights using historical and future viewing data sets.\nThe U.S. Mid-Atlantic has seen higher rates of sea level rise, marshes may be especially vulnerable. “In the Chesapeake Bay, sea level rise has already contributed to the degradation of over 80,000 ha (70%) of tidal marsh” (Taylor et al. 2020). This view can help us to understand the impacts that small levels of sea level rise have on land.\nWe can prompt the user to think about future impacts outside the direct sea level rise projections, allowing them to include a more full picture, and finally using that picture to identify economic impacts that action or inaction causes. This begs the question, what can the public do to enact changes, rather than putting the pressure on farmers to change?\n\n!pip install arcgis arcgis-mapping rasterio earthaccess\n\nRequirement already satisfied: arcgis in c:\\users\\jmartine\\appdata\\local\\esri\\conda\\envs\\agsdev\\lib\\site-packages (2.2.0)\n\n\n\n\n\n\n#import the required packages\nimport geopandas as gpd\nimport rasterio\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import box\nimport numpy as np\nimport requests\nimport xml.etree.ElementTree as ET\nimport matplotlib.pyplot as plt\nfrom io import BytesIO\nimport os\nfrom rasterio.warp import calculate_default_transform, reproject, Resampling\nfrom datetime import datetime, timedelta\n\n\n#define fuctions\n\ndef reproject_raster(src_dataset, src_crs, src_transform, dst_crs='EPSG:4326'):\n    dst_crs = rasterio.crs.CRS.from_string(dst_crs)\n    dst_transform, dst_width, dst_height = calculate_default_transform(\n        src_crs, dst_crs,\n        src_dataset.width, src_dataset.height,\n        *src_dataset.bounds)\n    dst_kwargs = src_dataset.meta.copy()\n    dst_kwargs.update({\n        'crs': dst_crs,\n        'transform': dst_transform,\n        'width': dst_width,\n        'height': dst_height})\n    dst_data = np.zeros((src_dataset.count, dst_height, dst_width), dtype=src_dataset.dtypes[0])\n    for i in range(1, src_dataset.count + 1):\n        reproject(\n            source=rasterio.band(src_dataset, i),\n            destination=dst_data[i-1],\n            src_transform=src_transform,\n            src_crs=src_crs,\n            dst_transform=dst_transform,\n            dst_crs=dst_crs,\n            resampling=Resampling.nearest)\n    return dst_data, dst_kwargs\n\ndef format_cdl_url(fips,year):\n    base_url = \"https://nassgeodata.gmu.edu/axis2/services/CDLService/GetCDLFile\"\n    url = f\"{base_url}?year={year}&fips={fips}\"\n    return url\n\ndef get_srl_raster():\n    slr_path = 'data/MD_East_slr_depth_3_5ft.tif'\n    with rasterio.open(slr_path) as slr_raster:\n            slr_meta = slr_raster.meta\n            slr_meta['nodata'] = 0\n            slr_reprojected, slr_meta_reprojected = reproject_raster(src_dataset=slr_raster, src_crs=slr_meta['crs'], src_transform=slr_meta['transform'])\n    return slr_reprojected, slr_meta_reprojected"
  },
  {
    "objectID": "NASA-Acres-Climate-Resilience-Network.html#combine-and-compare-the-results",
    "href": "NASA-Acres-Climate-Resilience-Network.html#combine-and-compare-the-results",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "Combine and compare the results",
    "text": "Combine and compare the results\n\nndvi_resampled, ndvi_resampled_meta = resample_using_cdl(ndvi, meta, cdl_meta_reprojected)\n\nslr_resampled, slr_resampled_meta = resample_using_cdl(slr_reprojected, slr_meta_reprojected, cdl_meta_reprojected)\n\nprint(\"CDL shape:\", cdl_reprojected.shape)\n\nprint(\"Original NDVI shape:\", ndvi.shape)\n\nprint(\"Resampled NDVI shape:\", ndvi_resampled.shape)\n\nprint(\"Original SLR shape:\", slr_reprojected.shape)\n\nprint(\"Resampled SLR shape:\", slr_resampled.shape)\n\nCDL shape: (1, 1681, 2153)\nOriginal NDVI shape: (9, 166, 402)\nResampled NDVI shape: (9, 1681, 2153)\nOriginal SLR shape: (1, 44790, 28460)\nResampled SLR shape: (1, 1681, 2153)\n\n\n\ndef mask_rasters(cdl_raster, slr_raster, ndvi_rasters):\n\n    corn_mask = cdl_raster == 1\n\n    ABOVE_water_mask = slr_raster <= 1\n\n    corn_above_water_mask = corn_mask & ~ABOVE_water_mask\n\n    corn_below_water_mask = corn_mask & ABOVE_water_mask\n\n    corn_above_water_mask = corn_above_water_mask[0,:,:]\n\n    corn_below_water_mask = corn_below_water_mask[0,:,:]\n\n    masked_ndvi_below_water = ndvi_rasters[:, corn_below_water_mask]\n\n    masked_ndvi_above_water = ndvi_rasters[:, corn_above_water_mask]\n\n    return {\n\n        'corn_below_water': {\n\n            'mask': corn_below_water_mask,\n\n            'ndvi': masked_ndvi_below_water,\n\n            'mean': np.mean(masked_ndvi_below_water, axis=1) if masked_ndvi_below_water.size > 0 else None,\n\n            'min': np.min(masked_ndvi_below_water, axis=1) if masked_ndvi_below_water.size > 0 else None,\n\n            'max': np.max(masked_ndvi_below_water, axis=1) if masked_ndvi_below_water.size > 0 else None\n\n        },\n\n        'corn_above_water': {\n\n            'mask': corn_above_water_mask,\n\n            'ndvi': masked_ndvi_above_water,\n\n            'mean': np.mean(masked_ndvi_above_water, axis=1) if masked_ndvi_above_water.size > 0 else None,\n\n            'min': np.min(masked_ndvi_above_water, axis=1) if masked_ndvi_above_water.size > 0 else None,\n\n            'max': np.max(masked_ndvi_above_water, axis=1) if masked_ndvi_above_water.size > 0 else None\n\n        }\n\n    }\n\n\ndef visualize_ndvi_analysis(ndvi_analysis, days):\n\n    plt.figure(figsize=(12, 6))\n\n    plt.subplot(1, 2, 1)\n\n    plt.plot(days, ndvi_analysis['corn_above_water']['mean'], label='Corn Above Water', color='green')\n\n    plt.plot(days, ndvi_analysis['corn_below_water']['mean'], label='Corn Below Water', color='blue')\n\n    plt.title('Mean NDVI')\n\n    plt.xlabel('Days')\n\n    plt.xticks(rotation=90)\n\n    plt.ylabel('NDVI')\n\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n\n    plt.plot(days, ndvi_analysis['corn_above_water']['max'], label='Corn Above Water', color='green')\n\n    plt.plot(days, ndvi_analysis['corn_below_water']['max'], label='Corn Below Water', color='blue')\n\n    plt.title('Maximum NDVI')\n\n    plt.xlabel('Days')\n\n    plt.xticks(rotation=90)\n\n    plt.ylabel('NDVI')\n\n    plt.legend()\n\n    plt.tight_layout()\n\n    plt.show()\n\n\nndvi_analysis = mask_rasters(cdl_reprojected, slr_resampled, ndvi_resampled)\n\nvisualize_ndvi_analysis(ndvi_analysis, day)\n\n\n\n\n\nfor condition in ['corn_below_water', 'corn_above_water']:\n\n    print(f\"\\n{condition.replace('_', ' ').title()} Corn Analysis per MODIS:\")\n\n    for stat in ['mean', 'max']:\n\n        print(f\"{stat.capitalize()} NDVI: {ndvi_analysis[condition][stat]}\")\n\n\nCorn Below Water Corn Analysis per MODIS:\nMean NDVI: [21.55594865 20.51568452  7.4782058  26.24400004 26.60275338 23.33767715\n 13.16068297 11.80940537 12.10314245]\nMax NDVI: [81.11699055 76.91399092 80.58758897 82.75593908 89.70690955 91.41303851\n 88.49125289 85.55169137 90.92957006]\n\nCorn Above Water Corn Analysis per MODIS:\nMean NDVI: [54.61076598 59.69546623 65.22443398 65.90975493 78.52357012 76.01061572\n 73.06511618 54.97502392 54.67252283]\nMax NDVI: [95.95130762 89.55483178 90.90481424 95.45510286 96.85160514 99.7260847\n 93.69302615 98.97050876 96.44831104]\n\n\n\ndef visualize_ndvi_histogram(ndvi_analysis):\n\n    plt.figure(figsize=(12, 6))\n\n    plt.hist(ndvi_analysis['corn_below_water']['ndvi'].flatten(), bins=30, alpha=0.5, label='Corn Below Water', color='blue')\n\n    plt.hist(ndvi_analysis['corn_above_water']['ndvi'].flatten(), bins=30, alpha=0.5, label='Corn Above Water', color='green')\n\n    plt.xlabel(\"NDVI values\")\n\n    plt.ylabel(\"Frequency\")\n\n    plt.title(\"Histogram of NDVI values for corn\")\n\n    plt.legend(loc='upper right')\n\nvisualize_ndvi_histogram(ndvi_analysis)\n\n\n\n\nWhat are the insights that we can derive from this module?\nWhat are the impacts of land being close to the water currently?\nWhat is the potential loss of productive land?\nWhere could there be errors given the sampling methods?"
  },
  {
    "objectID": "NASA-Acres-Climate-Resilience-Network.html#nasa-acres",
    "href": "NASA-Acres-Climate-Resilience-Network.html#nasa-acres",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "NASA Acres",
    "text": "NASA Acres\nNASA Acres is NASA’s U.S.-focused agriculture and food security Consortium. NASA Acres is commissioned under NASA’s Applied Sciences Program and led by the University of Maryland, with over 30 partner institutions and growing. The consortium approach brings together public and private sectors, and allows for flexible partnerships and rapid action in delivering the benefits of NASA data and tools to U.S. agriculture decision makers. We work with people across the agriculture sector to develop Earth observation (EO)-based data and tools that strengthen U.S. agriculture."
  },
  {
    "objectID": "NASA-Acres-Climate-Resilience-Network.html#climate-resilience-network",
    "href": "NASA-Acres-Climate-Resilience-Network.html#climate-resilience-network",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "Climate Resilience Network",
    "text": "Climate Resilience Network\nClimate Resilience Network has the goal of unifying the University of Maryland’s groundbreaking research with the immediate requirements of Maryland’s decision-makers to address the complexities of climate change as it affects our home. GEOG’s Grand Challenges project is aimed at promoting climate-resilient agriculture in Maryland, creating interactive tools designed to support research based decision-making.italicized text\nCOUNTY LEVEL SHAPEFILE https://resilience.climate.gov/datasets/nationalclimate::u-s-climate-and-coastal-inundation-projections-by-geography/explore?layer=0&location=2.619718%2C0.314282%2C1.74"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome SCHOOL Module 4: Climate and Agriculture",
    "section": "",
    "text": "Welcome to the fourth module of the SCHOOL curriculum!\nThe Science Core Heuristics for Open Science Outcomes in Learning (SCHOOL) is part of the NASA Transform to Open Science (TOPS) Training (TOPST) initiative, designed to teach the data science lifecycle using data from the NASA Earth Sciences division and to foster an inclusive culture of open science. You can learn more about the SCHOOL Project and other modules on the SCHOOL Project home page.\nThis TOPS SCHOOL module on the theme of ’Climate and Agriculture” provides a foundational understanding of the complex interplay between Earth’s ecosystems, climate and human-induced climate change, and environmental justice. We will explore how we can use spatial data for the study of climate, agriculture, and their impacts on vulnerable communities. You will also gain critical insights into how a changing climate affect agricultural resources people rely on for food. As you engage with the lessons, you will develop a comprehensive understanding of key concepts of earth’s climate system, the significance of social vulnerability to climate risks, and the tools available for analyzing environmental and agricultural data. Ultimately, these lessons will empower you to contribute meaningfully to discussions and actions pertaining to earth’s climate, agricultural systems, and environmental justice."
  },
  {
    "objectID": "index.html#module-4-climate-and-agriculture-datasets-and-use-cases-cover",
    "href": "index.html#module-4-climate-and-agriculture-datasets-and-use-cases-cover",
    "title": "Welcome SCHOOL Module 4: Climate and Agriculture",
    "section": "Module 4: Climate and Agriculture datasets and use cases cover:",
    "text": "Module 4: Climate and Agriculture datasets and use cases cover:\n\nUnderstanding Human Exposure to Heat: This lesson will use Google Earth Engine to analyze temperature and social vulnerability data.\n\nLesson 1: Understanding Human Exposure to Heat\n\nFlash Drought Multi-Indicator Analysis: This lesson will use R and open source R packages to work with multiple drought indicators to understand rapid drought intensification and its agricultural impacts.\n\nLesson 3: Flash Drought Multi-Indicator Analysis\n\nNASA ACRES Climate Resilience Network: This lesson will use public research data for derived conclusions and to view the impacts climate change has on agriculture.\n\nLesson 4: NASA ACRES Climate Resilience Network\n\n\n\nStart Lesson 1\n\nThis course was made possible thanks to the work of our NASA Transform to Open Science (TOPS) team, our SCHOOL Open Science team, open science Subject Matter Experts (SMEs), and the SCHOOL Development team!"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "",
    "text": "Test"
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html",
    "href": "m401-nasa-acres-climate-resilience-network.html",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "",
    "text": "Technical Skills:\n\nAccess and process satellite imagery using NASA’s APPEARS platform\nWork with different spatial data formats and resolutions\nPerform raster analysis and visualization\nCalculate and interpret NDVI values from multispectral satellite data\n\nAnalytical Skills:\n\nCompare vegetation health between areas affected and unaffected by saltwater intrusion\nEvaluate limitations and uncertainties in geospatial analysis\n\n\n\n\nUnderstand the relationship between sealevel rise, salt water intrusion, and agricultural productivity in Maryland’s coastal regions\nLearn to work with and analyze multiple types of geospatial data (raster datasets) using Python\nInterpret vegetation health patterns using satellite-derived NDVI measurements\nEvaluate potential future impacts of sea level rise on agricultural land\n\nThis lesson will allow the learner to gain a deper understanding of the followinf concepts - Recognizing the economic importance of agriculture in Maryland - Understanding how sea level rise is impacting coastal farming - Identifying the role of remote sensing in monitoring environmental changes - Connecting local agricultural challenges to broader climate change impacts\nThis module can help to contextualize the impact of saltwater inundation. For this module, we will identify cropland, and then, using the NOAA sea level rise estimations, we can calculate the difference in productivity using NDVI as a measure of vegetation health. A graphical time series allows us to see areas impacted by sea level rise.\nFirst, we can find the county-level statistics of harvestable acreage. We are using the Crop Data Layer (CDL) from the United States Department of Agriculture National Agriculture Statistics Service (USDA NASS)\n\nUse API to call in the CDL dataset to map crop types.\n\nAfter getting familiar with the dataset, we can modify it. Because we are interested in the impact of sea level rise and the effect we can find that data from the National Oceanic and Atmospheric Administration\n\nAccess the Sea level rise (elevation dataset) to identify new areas of potential areas that are at risk of future flooding. Clip to county of interest\nCompare the CDL with the SLR mask and without to identify the NOAA estimated loss of land.\n\nThen using Landsat create a time series for the Normalized Difference Vegetation Index (NDVI) of the masked cropland, derive insights about trends in NDVI.\n\nUse NDVI to create a time series looking back in time at areas that have experienced flooding to visualize the movement from productive farms to moderate quality.\n\nThis all together would allow us to make a predictive analysis for Maryland in the future under the projections of sea level rise. Given the current conditions, subtracting the sea level rise inundated areas.\nThe data story we have derived concerns sea level rise in Maryland and its impact on production levels within the state. This module can help students draw from multiple data sources and derive insights using historical and future viewing data sets.\nWe can prompt the user to think about future impacts outside the direct sea level rise projections, allowing them to include a full picture and finally using that picture to identify economic impacts that action or inaction causes. This begs the question: What can the public do to enact changes rather than putting pressure on farmers to change?"
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#nasa-acres",
    "href": "m401-nasa-acres-climate-resilience-network.html#nasa-acres",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "NASA Acres",
    "text": "NASA Acres\nNASA Acres is NASA’s consortium focused on agriculture and food security in the United States.\n1\nNASA Acres brings together actors throughout the agricultural community to share methods, data, and technology to work towards a richer knowledge about past and present agricultural land use, productivity, and sustainability in the U.S. The mission is also to create a stronger agricultural technology workforce ready to tackle the challenges of climate change and global hazards to U.S. agriculture and food security.\nNASA Acres has defined the Essential Agricultural Variables (EAVs) to address this problem. These were designed by NASA Acres to define the capabilities of the top satellite data scientists and practitioners who make up NASA Acres Research, Development, and Extension partners, and the needs of decision-making-collaborators already in our network, to identify an initial set of focus.\n\nCropland and Crop Type Mapping\nCrop and Crop Type Area Estimation\n\nThis can help us determine the changes in the cropland. As things change, we can tell how much and what is actually changing because we have mapped and studied this area. The need for accurate, consistent study within these areas of agriculture is vital for describing changes as they occur.\n\nWhat is Remote Sensing?\nRemote sensing is the action of measuring the reflectance of energy from objects. For this module we are using Landsat, a passive satellite that relies on the sun to send out energy and the sensor measures the reflectance.\n\nFrom this, we can use both the visible (red, green, blue) reflectance and the infrared light to detect objects on the ground.\nThis is an example of a Landsat image. Compared to the aerial image, the Landsat image appears pixelated. This is because Landsat takes all the reflectances within each 30 by 30-meter square in the ground to get one value.\n\nGenerate the pull for the NDVI data. This data pull comes from The Application for Extracting and Exploring Analysis Ready Samples (AppEEARS), which offers a simple and efficient way to access data archives. We will use Landsat for this module, but a variety of datasets are available.\n\nNDVI is a commonly used calculation as an indicator for the health of vegetation based on the ratio of reflectance of red to near-infrared values within the electromagnetic spectrum. If you want to learn more."
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#why-agriculture",
    "href": "m401-nasa-acres-climate-resilience-network.html#why-agriculture",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "WHY AGRICULTURE?",
    "text": "WHY AGRICULTURE?\nAccording to the United States Department of Agriculture (USDA) in 2023 farming operations in Maryland (MD) were an estimated 2,000,000 acres. For grain corn in MD, in 2023, 440,000 acres were harvested. The total commercial value for all corn in the state was $355,740,000.\nFood is a vital resource for direct and indirect consumption. However, as salt water intrudes into agricultural land, the impacts and consequences are just beginning to be felt.\nAs researchers, we must come to the same understanding of what is important in order to understand why we are studying agriculture."
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#climate-smart-agriculture-in-maryland",
    "href": "m401-nasa-acres-climate-resilience-network.html#climate-smart-agriculture-in-maryland",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "CLIMATE SMART AGRICULTURE IN MARYLAND",
    "text": "CLIMATE SMART AGRICULTURE IN MARYLAND\nWhy is agriculture important in Maryland and what is salt water intrusion?\nResearchers found that salt was intruding on coastal agricultural areas.\nSaltwater impacted coastal farming on a broad scale. Although there was some debate around the area lost, estimates put land losses between 8,000 to 140,000 ha of surface inundation (Mondal et al. 2023; Taylor et al. 2020).\n2\nResearchers use satellite remote sensing to develop machine learning models built on ground-truthed data to identify salt patches in the mid-Atlantic region of the US.\nThe U.S. Mid-Atlantic has seen higher rates of sea level rise, marshes may be especially vulnerable. “In the Chesapeake Bay, sea level rise has already contributed to the degradation of over 80,000 ha (70%) of tidal marsh” (Taylor et al. 2020). This view can help us understand the impacts of small sea level rise on land.\n\nSaltwater Intrusion\nTo understand more about saltwater intrusion in Maryland, run this code and watch the video that explains the causes and effects.\n\nLearn more about saltwater inundation from the National Oceanic and Atmospheric Administration program titled Coastal Farming Challenges: Flooding, Salt, and Land Loss.\nBelow is a simplified illustration of saltwater intrusion:\n3"
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#introductory-code",
    "href": "m401-nasa-acres-climate-resilience-network.html#introductory-code",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "INTRODUCTORY CODE",
    "text": "INTRODUCTORY CODE\n\nAccessing Data\nNASA Earth data requires a data pull request, this takes time to ‘order’, we can run this now to give the program time to gather the data we are requesting. This code chunk is used for local downloads if you have not yet downloaded data:\n\n## NASA Earth Data username and password\n# USERNAME = \"USERNAME\" ## ENTER HERE\n# PASSWORD = \"PASSWORD\" ## ENTER HERE\n\n## The submit the Landsat tiles, we have provided you with the geojson file of Talbot County.\n## If you wish to use another county, download, and path to the other county geojson file\ncounty_path = 'data/Talbot_County.geojson' # Path to county\n\n\n# Conversion to geopandas data frame\ncounty_data =  gpd.read_file(county_path)\n # Reproject the county_data to landsat\ncounty_reprojected = county_data.to_crs('EPSG:4326')\n\nyear = 2018 # Year of interest\n\n\n\nCreating an APPEEARS token\nAccessing data directly from the NASA Earthdata Cloud APPEEARS website requires to make a request with your Earthdata Username and Password. This request generates a token:\n\n# Get the token from your Earth Data account\ntoken = requests.post('https://appeears.earthdatacloud.nasa.gov/api/login',auth=(USERNAME, PASSWORD)).json()['token']\n\nWith the token, you can create an APPEEARS task that requests a data package. An email is sent to you with confirmation and updates on your request. NOTE: This requrest may take a few hours to be filled.\n\n# task = {'task_type': 'area',\n#           'task_name': 'Talbot_County',\n#           'params': {\n#                     'dates': [{'startDate':  f'06-01-{year}' , 'endDate': f'09-30-{year}'}],# Set the start and end dates for summer sections\n#                     'layers': [{'layer': 'SR_B4', 'product':'L08.002'},\n#                                {'layer': 'SR_B5', 'product':'L08.002'}], # Data of interest is the NDVI values\n#                     'geo': { #The geo field should contain the geoJSON, currently it is in a set\n#                         'type': 'FeatureCollection',\n#                         'features': [{\n#                             'type': 'Feature',\n#                             'properties': {},\n#                             'geometry': county_reprojected.geometry.iloc[0].__geo_interface__ #Extracting the geometry from the GeoPandas DataFrame as a GeoJSON-compatible dictionary\n#                         }]\n#                     },\n#                     \"output\": {\"format\": {\"type\": \"geotiff\"},\n#                               \"projection\": \"native\"}}}\n\n# task_id = requests.post('https://appeears.earthdatacloud.nasa.gov/api/task',json=task,headers={'Authorization': f'Bearer {token}'}).json()\n\nYou should receive an email from APPEEARS that says the task has started."
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#working-with-rasters",
    "href": "m401-nasa-acres-climate-resilience-network.html#working-with-rasters",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "Working with Rasters",
    "text": "Working with Rasters\n\nReading Raster Data\nThere are two ways to display information: vectors (points, lines, polygons) or rasters. Rasters are continuous sheets that are layered across a space; they are made up of pixels. Each pixel represents the ground beneath it. For example, if a raster pixel is 30 by 30 meters, that means a single pixel represents 30 by 30 meters on the ground.\n\nfips = \"24041\" # County code for all US counties, remember we called this in the first code chunk when we used the geojson to gather Landsat NDVI images\nyear = 2018 # Year of interest\n\n# The CDL (crop data layer) is the authoritative data layer for the US crops\nbase_url = \"https://nassgeodata.gmu.edu/axis2/services/CDLService/GetCDLFile\"\n\n# Pulling the data from the online source using the requests library allows us to access the data without needing to download the dataset\nresponse = requests.get(f\"{base_url}?year={year}&fips={fips}\")\nprint(response.content)\nroot = ET.fromstring(response.content)\ntif_url = root.find('.//returnURL').text\ncdl_data = rasterio.open(tif_url)\ncdl_meta = cdl_data.meta\ndata = cdl_data.read(1)\n\nb'&lt;ns1:GetCDLFileResponse xmlns:ns1=\"http://cropscape.csiss.gmu.edu/CDLService/\"&gt;&lt;returnURL&gt;https://nassgeodata.gmu.edu/webservice/nass_data_cache/byfips/CDL_2018_24041.tif&lt;/returnURL&gt;&lt;/ns1:GetCDLFileResponse&gt;'\n\n\n\n\nDisplaying Raster Data\nMISSING TEXT\n\nbounds = transform_bounds(cdl_data.crs, 'EPSG:4326', *cdl_data.bounds)\n\n# Calculate the center of the image for the map\ncenter_lat = (bounds[1] + bounds[3]) / 2\ncenter_lon = (bounds[0] + bounds[2]) / 2\n\n# Create a base map centered on the image\nm = folium.Map(location=[center_lat, center_lon], zoom_start=10)\n\n# Add the raster layer to the map\nimg = folium.raster_layers.ImageOverlay(\n    data,\n    bounds=[[bounds[1], bounds[0]], [bounds[3], bounds[2]]],\n\n)\nimg.add_to(m)\n\n# Add the colormap to the map\n\n# Add layer control\nfolium.LayerControl().add_to(m)\ndisplay(m)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nZoom around in on the map. Look at the raster structure, the squares stacked next to each other, representing an area on the ground.\n\n\nSpatially Project Raster Data\nWhen working with geographic data, we have to begin by knowing that all of our data is in the right space on the globe. We begin with a function for reprojecting rasters. This is one of the keys when working with spatial data: ensuring that all of the data is based on the same spatial reference.\nReprojecting requires a resampling method; for this, we use the nearest neighbor’s resampling.\n\n\ndef reproject_raster(src_dataset, src_crs, src_transform, dst_crs):\n    # Convert the destination CRS string into a CRS object that rasterio can use\n    # For example, 'EPSG:4326' becomes a python coordinate object\n    dst_crs = rasterio.crs.CRS.from_string(dst_crs)\n\n    # Calculate the new dimensions and transformation matrix for the output raster\n    # This ensures the whole image fits in the new coordinate system\n    dst_transform, dst_width, dst_height = calculate_default_transform(\n        src_crs,                    # Current coordinate system\n        dst_crs,                    # Target coordinate system\n        src_dataset.width,          # Current image width\n        src_dataset.height,         # Current image height\n        *src_dataset.bounds         # The geographical bounds of the image\n    )\n\n    # Copy the metadata from the source dataset\n    # This includes things like data type, number of bands, etc.\n    dst_kwargs = src_dataset.meta.copy()\n\n    # Update the metadata with the new CRS, transform, width, and height\n    dst_kwargs.update({\n        'crs': dst_crs,\n        'transform': dst_transform,\n        'width': dst_width,\n        'height': dst_height\n    })\n\n    # Create an empty array to store the reprojected data\n    # Shape is (number of bands, new height, new width)\n    dst_data = np.zeros((src_dataset.count, dst_height, dst_width),\n                       dtype=src_dataset.dtypes[0])\n    reproject(\n        source=rasterio.band(src_dataset,1),\n        destination=dst_data,             # Where to store the result\n        src_transform=src_transform,           # Current transformation\n        src_crs=src_crs,                      # Current coordinate system\n        dst_transform=dst_transform,           # New transformation\n        dst_crs=dst_crs,                      # New coordinate system\n        resampling=Resampling.nearest         # Use nearest neighbor resampling\n    )\n\n    # Return both the reprojected data and the updated metadata\n    return dst_data, dst_kwargs\n\n\n\nAccess data with API\nTo understand the nature of Maryland agriculture we can begin by using the CDL. This raster dataset comes at a 30-meter spatial resolution. We can access this data through their API. The current configuration allows data to be pulled at the county level.\nCOUNTY LEVEL CDL FOR FIPS\nThis view provides insight into the common commodities that are grown in Maryland in the desired year.\n\ncdl_reprojected, cdl_meta_reprojected = reproject_raster(cdl_data, cdl_meta['crs'], cdl_meta['transform'], 'EPSG:4326')\n\nThe eastern seaboard has seen changes in the sea level along with increased flooding and the decrease in the predictability of water flow from rivers. This data comes from NOAA, this raster is the projection of inundated areas by the year 2050. Data access can be found here.\nAmazon AWS S3 Bucket - Cloud Access to the data:\n\n# S3 path to the sea level rise TIFF file\nslr_s3_url = \"https://tops-school.s3.us-west-2.amazonaws.com/climate-agriculture-module/MD_East_slr_depth_3_5ft.tif\"\n\n# Convert S3 URL to GDAL-compatible format\nslr_s3_gdal_path = \"/vsicurl/\" + slr_s3_url  # Allows rasterio to read from S3 directly\n\n# Open the raster from S3, then reproject\nwith rasterio.open(slr_s3_gdal_path) as slr_raster:\n    slr_meta = slr_raster.meta.copy()\n    slr_meta['nodata'] = 0  # Set nodata value\n\n    # Reproject\n    slr_reprojected, slr_meta_reprojected = reproject_raster(\n        slr_raster,\n        slr_meta['crs'],\n        slr_meta['transform'],\n        'EPSG:4326'\n    )\n\nIf you’ve downloaded the data locally:\n\n# # Path to the stored sea level rise tif file\n# slr_path = 'data/MD_East_slr_depth_3_5ft.tif'\n\n# # This allows us to open the raster file, then reproject and close the original file so we are not storing duplicates of the raster\n# with rasterio.open(slr_path) as slr_raster:\n#     slr_meta = slr_raster.meta.copy()\n#     slr_meta['nodata'] = 0\n\n#     # Reproject\n#     slr_reprojected, slr_meta_reprojected = reproject_raster(\n#         slr_raster,\n#         slr_meta['crs'],\n#         slr_meta['transform'],\n#         'EPSG:4326')\n\n\n\nWorking with NASA APPEEARS Data\nYou should have received an email from APPEEARS letting you know your task has completed. If you have not received this, go to the APPEEARS website to view the progress by clicking on the explore tab and viewing the TALBOT_COUNTY request.\n\n## NASA hosts their Landsat data in their program called APPEEARS\n# To access the data you must probe it from cold storage, that was the initial code we ran\n# If you wish to learn more, visit the API documentation from appeears\ndef doy_2_date(day_of_year_str): # This function changes the DOY value to a more easily readable format (from Julian day of the year to date based on month day year)\n              year = int(day_of_year_str[:4]) # year string to integer\n              day_of_year = int(day_of_year_str[4:]) # Julian day string to integer\n              start_date = datetime(year, 1, 1) # using datetime to change year to first day first month of the year of interest\n              target_date = start_date + timedelta(days=day_of_year - 1) # add the DOY of acquisition to the year\n              return target_date.strftime('%m-%d-%Y') ## return proper formatting\n\nThe token and Task ID created previously for APPEEARS can be used here to create a ‘bundle’ which carries multiple datasets from APPEEARS\n\nbundle = requests.get(f'https://appeears.earthdatacloud.nasa.gov/api/bundle/{task_id[\"task_id\"]}',headers={'Authorization': f'Bearer {token}'}).json()\nQA_data = {}\ndata = {} # Create an empty dictionary to collect the data from appeears\n\n\nfor file in bundle['files']: # loops through each Landsat tile that we called.\n    file_id = file['file_id'] # store the name of the tile\n    if '_doy' in file['file_name']: \n        # doy is the day of the year, ordering the dictionary by doy allows for easier access later\n        # This allows us to get just the files of interest. We only want the\n        if \"SR_B4\" in file['file_name'] or \"SR_B5\" in file['file_name'] or \"QA_PIXEL_C\" in file['file_name']:\n            datesy = file['file_name'].split('_doy')[1][:7] # seperation of doy values\n            doy = doy_2_date(datesy) # calling the function (from Julian day (001 is the first day of the year, 365 is the last day of the year) to mm-dd-yyyy\n            band = file['file_name'].split('/L08.002_')[1][:5]\n            # access the NDVI data via request library\n            file_download = requests.get('https://appeears.earthdatacloud.nasa.gov/api/bundle/{0}/{1}'.format(task_id['task_id'], file_id), headers={'Authorization': 'Bearer {0}'.format(token)}, allow_redirects=True, stream=True)\n            # Get the status of the file\n            file_download.raise_for_status()\n            # This error warning allows for continuation even if there is an error\n            if not file_download.content:\n                print(f\"Warning: Empty file downloaded for {file['file_name']}\") # print warning message if there is an error, continue to next data set otherwise\n                continue\n            file_content = BytesIO(file_download.content) # format the downloaded content\n            with rasterio.open(file_content) as src_initial: # open the accessed raster\n                src = src_initial.read(1, masked=True) # read in the layer data\n                src_meta = src_initial.meta # access the metadata\n                dst_crs = 'EPSG:4326' # define the crs\n                transform, width, height = calculate_default_transform(\n                    src_meta['crs'], dst_crs, src.shape[1], src.shape[0], *src_initial.bounds)\n                kwargs = src_meta.copy()\n                # collect the current meta data information\n                kwargs.update({\n                    'crs': dst_crs,\n                    'transform': transform,\n                    'width': width,\n                    'height': height\n                })\n\n                dst = np.zeros((height, width), dtype=src_meta['dtype'])\n                # Begin the reprojection process based on earlier defined projections of interest\n                reproject(\n                    source=src,\n                    destination=dst,\n                    src_transform=src_meta['transform'],\n                    src_crs=src_meta['crs'],\n                    dst_transform=transform,\n                    dst_crs=dst_crs,\n                    resampling=Resampling.nearest)\n\n                # update the data (if no data set to 0)\n                kwargs.update({'nodata': 0})\n                # name the data\n                key = f'{band}'\n                if key not in data:\n                    # if first dataset, append the metadata to the entire dictionary\n                    data[key] = {'data': [], 'meta': kwargs, 'doy': []}\n                # stack the data and data\n                data[key]['data'].append(dst)\n                data[key]['doy'].append(doy)\n        else:\n          continue\n\n    else:\n      continue\n\nExtract some of the data into variables\n\n# name the stacked data, day, and metadata to be referenced later\nnir = np.stack(data['SR_B5']['data']) / 1000\nred = np.stack(data['SR_B4']['data']) / 1000\nqa_flags = np.stack(data['QA_PI']['data'])\nday = np.stack(data['SR_B5']['doy'])\nmeta_nir = data['SR_B5']['meta']\nmeta_red = data['SR_B4']['meta']\n\n#handing 0 and NaN values when dividing\ndenominator = nir + red\ndenominator = np.where(denominator == 0, np.nan, denominator)  # Avoid division by zero\nndvi = (nir - red) / denominator  # Compute NDVI safely\nndvi = np.nan_to_num(ndvi, nan=0)\n\nNow that we have an NDVI dataset for each date, we have to filter out the cloudy or otherwise poor-quality NDVI values.\n\n\nqa_flags_to_mask = [21824, 21890, 21952, 22018, 22146, 22208] ## These are the values that indicate the higher quality of pixel\nmasked_ndvi = np.where(np.isin(qa_flags, qa_flags_to_mask), np.nan, ndvi) # filter the NDVI array\n\n\n## This function resamples the data to the same\n# Because the NDVI is 30 by 30-meters, the CDL data is at 30 by 30-meter resolution, and the SLR is less than 10 by 10-meter resolution\n# Resampling to the same spatial scale allows for analysis on the same spatial scale\ndef resample_data(data, data_meta, to_reproject, method):\n    # collect the metadata from the CDL dataset\n    resampled_data = np.zeros(\n        (data.shape[0], to_reproject['height'], to_reproject['width']),\n        dtype=data.dtype\n    )\n    # collect the metadata from the target dataset\n    for i in range(data.shape[0]): # Because the NDVI stack has multiple dates, we have to loop through the stacked data\n        reproject(\n            source=data[i],\n            destination=resampled_data[i],\n            src_transform=data_meta['transform'],\n            src_crs=data_meta['crs'],\n            dst_transform=to_reproject['transform'],\n            dst_crs=to_reproject['crs'],\n            resampling=method # method of resampling - either nearest neightbor or bilinear (average of 4 closest neighbors)\n        )\n    # update the target dataset to the CDL dataset height and width\n    updated_meta = data_meta.copy()\n    updated_meta.update({\n        'transform': to_reproject['transform'],\n        'width': to_reproject['width'],\n        'height': to_reproject['height'],\n        'crs': to_reproject['crs']\n    })\n\n    return resampled_data, updated_meta\n\ncdl_resampled, cdl_resampled_meta = resample_data(cdl_reprojected, cdl_meta_reprojected, meta_red, Resampling.nearest)\nslr_resampled, slr_resampled_meta = resample_data(slr_reprojected, slr_meta_reprojected, meta_red, Resampling.bilinear)\n\n# print out the dataset shapes to see how the transformation has changed the resolution of the data\nprint(\"NDVI shape:\", ndvi.shape)\n\nprint(\"Original CDL shape:\", cdl_reprojected.shape)\nprint('Resampled CDL:', cdl_resampled.shape)\n\nprint(\"Original SLR shape:\", slr_reprojected.shape)\nprint(\"Resampled SLR shape:\", slr_resampled.shape)\n\nNDVI shape: (15, 1681, 2153)\nOriginal CDL shape: (1, 1681, 2153)\nResampled CDL: (1, 1681, 2153)\nOriginal SLR shape: (1, 44790, 28460)\nResampled SLR shape: (1, 1681, 2153)\n\n\nThis code places both rasters on the same map. We first select only corn (where the CDL value is equal to 1). Look on the CDL website if you are interested in other land classes.\n\n# Create corn and water masks\ncorn_mask = (cdl_resampled[0, :, :] == 1).astype(np.uint8)  # Corn is labeled as 1 in CDL\nSLR_MASK = (slr_resampled[0, :, :] &lt;= 10).astype(np.uint8)  # Areas predicted to be underwater\n\n# Visualize the masks\nfig, ax = plt.subplots(figsize=(15, 5))\nax.imshow(corn_mask, cmap='Greens', alpha=0.5, label=\"Corn Fields\")\nax.imshow(SLR_MASK, cmap='Blues', alpha=0.5, label=\"Flooded Areas\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate the area of overlap between the corn and water masks.\noverlap_mask = np.logical_and(corn_mask, SLR_MASK)\n\n# Get the resolution of the raster data (assuming both are the same)\nresolution = meta_red['transform'][0]  # Assuming the transform is consistent across all rasters\n# Calculate the area of each pixel in acres (1 acre = 43560 sq ft)\npixel_area_acres = (30 * 3.28084)**2 / 43560 # convert from 30 meters to acres\n\n# Calculate the total impacted area\nimpacted_acres = np.sum(overlap_mask) * pixel_area_acres\n\nprint(f\"Acres impacted by flooding in corn fields: {impacted_acres:.2f}\")\n\n# Calculate the area of corn based on the corn mask.\ncorn_area_acres = np.sum(corn_mask) * pixel_area_acres\nprint(f\"Total acres of corn: {corn_area_acres:.2f}\")\n\nAcres impacted by flooding in corn fields: 57.60\nTotal acres of corn: 36616.42\n\n\nWhat can we tell from the changes in corn acreage and the amount below\n\nGraphically view the changes in NDVI.\n\n# Ensure masks match NDVI shape (time, height, width)\ncorn_below_water_mask = np.expand_dims(corn_mask & SLR_MASK, axis=0)  # Add time axis\ncorn_below_water_mask = np.broadcast_to(corn_below_water_mask, masked_ndvi.shape)  # Match NDVI shape\n\ncorn_above_water_mask = np.expand_dims(corn_mask & ~SLR_MASK, axis=0)  # Add time axis\ncorn_above_water_mask = np.broadcast_to(corn_above_water_mask, masked_ndvi.shape)  # Match NDVI shape\n\n# Extract NDVI values using masks\nmasked_ndvi_below_water = np.where(corn_below_water_mask, masked_ndvi, np.nan)\nmasked_ndvi_above_water = np.where(corn_above_water_mask, masked_ndvi, np.nan)\n\n\n# Safe computation of NDVI statistics\ndef safe_stat(ndvi_array, func):\n    valid_values = np.where(~np.isnan(ndvi_array), ndvi_array, np.nan)\n    return func(valid_values, axis=(1, 2)) if np.any(~np.isnan(valid_values)) else 0\n\nndvi_analysis = {\n    'corn_below_water': {\n        'mask': corn_below_water_mask,\n        'ndvi': np.nan_to_num(masked_ndvi_below_water, nan=0),  # Replace NaN with 0\n        'mean': np.nan_to_num(safe_stat(masked_ndvi_below_water, np.nanmean), nan=0),\n        'min': np.nan_to_num(safe_stat(masked_ndvi_below_water, np.nanmin), nan=0),\n        'max': np.nan_to_num(safe_stat(masked_ndvi_below_water, np.nanmax), nan=0),\n    },\n    'corn_above_water': {\n        'mask': corn_above_water_mask,\n        'ndvi': np.nan_to_num(masked_ndvi_above_water, nan=0),  # Replace NaN with 0\n        'mean': np.nan_to_num(safe_stat(masked_ndvi_above_water, np.nanmean), nan=0),\n        'min': np.nan_to_num(safe_stat(masked_ndvi_above_water, np.nanmin), nan=0),\n        'max': np.nan_to_num(safe_stat(masked_ndvi_above_water, np.nanmax), nan=0),\n    }\n}\n\n\n# Plot the results\nplt.figure(figsize=(12, 6))\n\n# Mean NDVI Plot\nplt.subplot(1, 2, 1)\nplt.plot(day[:len(ndvi_analysis['corn_above_water']['mean'])], ndvi_analysis['corn_above_water']['mean'], \n         label='Corn Above Water', color='green', marker='o')\nplt.plot(day[:len(ndvi_analysis['corn_below_water']['mean'])], ndvi_analysis['corn_below_water']['mean'], \n         label='Corn Below Water', color='blue', marker='o')\nplt.title('Mean NDVI')\nplt.xlabel('Days')\nplt.xticks(rotation=90)\nplt.ylabel('NDVI')\nplt.legend()\nplt.grid(True, linestyle=\"--\")\n\n# Maximum NDVI Plot\nplt.subplot(1, 2, 2)\nplt.plot(day[:len(ndvi_analysis['corn_above_water']['max'])], ndvi_analysis['corn_above_water']['max'], \n         label='Corn Above Water', color='green', linestyle='dashed', marker='s')\nplt.plot(day[:len(ndvi_analysis['corn_below_water']['max'])], ndvi_analysis['corn_below_water']['max'], \n         label='Corn Below Water', color='blue', linestyle='dashed', marker='s')\nplt.title('Maximum NDVI')\nplt.xlabel('Days')\nplt.xticks(rotation=90)\nplt.ylabel('NDVI')\nplt.legend()\nplt.grid(True, linestyle=\"--\")\n\nplt.tight_layout()\nplt.show()\n\n# Print the NDVI analysis summary\nfor condition in ['corn_below_water', 'corn_above_water']:\n    print(f\"\\n{condition.replace('_', ' ').title()} Corn Analysis per tile:\")\n    for stat in ['mean', 'max']:\n        print(f\"{stat.capitalize()} NDVI: {ndvi_analysis[condition][stat]}\")\n\n\n\n\n\n\n\n\n\nCorn Below Water Corn Analysis per tile:\nMean NDVI: [ 0.16744904  0.         -0.00791014  0.          0.          0.22444624\n -0.02143939  0.20328358  0.30109085  0.09892208  0.18618126  0.16381267\n  0.02174798  0.          0.19353319]\nMax NDVI: [0.47399746 0.         0.03439118 0.         0.         0.43567463\n 0.00174968 0.51706749 0.42077698 0.49697923 0.45352128 0.48780846\n 0.04795939 0.         0.26677634]\n\nCorn Above Water Corn Analysis per tile:\nMean NDVI: [ 0.14892067  0.1257956  -0.00682232  0.16759407  0.38214114  0.2080633\n -0.0182513   0.22864079  0.36927499  0.24962071  0.29803015  0.20926957\n  0.02514324  0.20202984  0.16798664]\nMax NDVI: [0.5760885  0.19840204 0.0955997  0.34410414 0.45413914 0.58097555\n 0.00197202 0.74051588 0.5811157  0.62020275 0.63945886 1.\n 0.07461124 0.47935368 0.63151341]\n\n\nWe can see that it is currently in trouble because the NDVI values are already lower, but we also know the number of acres impacted. What are the estimations for the loss of land? Building on that, what other areas beyond these calculations might be impacted as the sea rises?\nWe can see that the corn predicted to be below water in 2050 is already showing signs of decreased NDVI values. As the sea level continues to rise and salinization impacts farmers, what are the future conditions for corn growing in Maryland? What are the estimated impacts? What can we do?\n\n# Final Analysis and Reflection Section\n\n# Cropland and Crop Type Mapping Insights\ncropland_impact = {\n    'total_corn_acres': corn_area_acres,\n    'projected_flooded_acres': impacted_acres,\n    'percent_at_risk': (impacted_acres / corn_area_acres) * 100\n}\n\n# Crop Area Estimation Insights\nndvi_trend_analysis = {\n    'below_water_ndvi_mean': np.mean(ndvi_analysis['corn_below_water']['mean']),\n    'above_water_ndvi_mean': np.mean(ndvi_analysis['corn_above_water']['mean']),\n    'productivity_difference': np.mean(ndvi_analysis['corn_above_water']['mean']) - np.mean(ndvi_analysis['corn_below_water']['mean'])\n}\n\n# Print Narrative Report\nprint(\"\\n--- NASA Acres Essential Agricultural Variables (EAV) Analysis ---\")\nprint(f\"Total Corn Acreage: {cropland_impact['total_corn_acres']:.2f} acres\")\nprint(f\"Projected Flood Impact: {cropland_impact['projected_flooded_acres']:.2f} acres\")\nprint(f\"Percentage of Corn Land at Risk: {cropland_impact['percent_at_risk']:.2f}%\")\nprint(f\"\\nNDVI Productivity Assessment:\")\nprint(f\"  Corn Above Water NDVI: {ndvi_trend_analysis['above_water_ndvi_mean']:.4f}\")\nprint(f\"  Corn Below Water NDVI: {ndvi_trend_analysis['below_water_ndvi_mean']:.4f}\")\nprint(f\"  Productivity Difference: {ndvi_trend_analysis['productivity_difference']:.4f}\")\n\n# Reflection on Broader Implications\nprint(\"\\nReflection:\")\nprint(\"This analysis demonstrates the critical importance of:\")\nprint(\"1. Continuous monitoring of agricultural lands\")\nprint(\"2. Understanding climate change impacts on crop productivity\")\nprint(\"3. Developing adaptive strategies for coastal agricultural communities\")\n\n\n--- NASA Acres Essential Agricultural Variables (EAV) Analysis ---\nTotal Corn Acreage: 36616.42 acres\nProjected Flood Impact: 57.60 acres\nPercentage of Corn Land at Risk: 0.16%\n\nNDVI Productivity Assessment:\n  Corn Above Water NDVI: 0.1838\n  Corn Below Water NDVI: 0.1021\n  Productivity Difference: 0.0818\n\nReflection:\nThis analysis demonstrates the critical importance of:\n1. Continuous monitoring of agricultural lands\n2. Understanding climate change impacts on crop productivity\n3. Developing adaptive strategies for coastal agricultural communities"
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#knowledge-check",
    "href": "m401-nasa-acres-climate-resilience-network.html#knowledge-check",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "Knowledge Check",
    "text": "Knowledge Check\nTest your knowledge from this module.\n\nWhat are the insights that we can derive from this module?\nWhat are the current impacts of land being close to the water?\nWhat is the potential loss of productive land?\nWhere could there be errors given the sampling methods?\n\nThis is where mapping and monitoring the changes in our farmland is crucial. We can identify, monitor, and track changes as they arise. We can apply this view to a historical view using earlier imagery or later imagery to track the newest updates, even applying models to highlight potential future views."
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#printing-and-sharing-results",
    "href": "m401-nasa-acres-climate-resilience-network.html#printing-and-sharing-results",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "Printing and Sharing Results",
    "text": "Printing and Sharing Results\nIf you want to download the tifs you created, you can do so here.\n\nSLR_output_tif_path = '' # Replace with your desired path\nslr_masked_int = SLR_MASK.astype(rasterio.uint8)\n\n\nwith rasterio.open(\n    SLR_output_tif_path,\n    'w',\n    driver='GTiff',\n    height=slr_resampled_meta['height'],\n    width=slr_resampled_meta['width'],\n    count=1,  # Number of bands in the output GeoTIFF\n    dtype=rasterio.uint8,\n    crs=slr_resampled_meta['crs'],\n    transform=slr_resampled_meta['transform'],\n    nodata=0 # Set nodata value if necessary\n) as dst:\n    dst.write(slr_masked_int, 1)\n\nprint(f\"Masked SLR saved to: {SLR_output_tif_path}\")\n\n\ncorn_maskoutput_tif_path = '' # Replace with your desired path\ncorn_mask_int = corn_mask.astype(rasterio.uint8)\n\n\nwith rasterio.open(\n    corn_maskoutput_tif_path,\n    'w',\n    driver='GTiff',\n    height=cdl_resampled_meta['height'],\n    width=cdl_resampled_meta['width'],\n    count=1,  # Number of bands in the output GeoTIFF\n    dtype=rasterio.uint8,\n    crs=cdl_resampled_meta['crs'],\n    transform=cdl_resampled_meta['transform'],\n    nodata=0 # Set nodata value if necessary\n) as dst:\n    dst.write(corn_mask_int, 1)\n\nprint(f\"Masked SLR saved to: {corn_maskoutput_tif_path}\")"
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#in-this-lesson-you-will",
    "href": "m401-nasa-acres-climate-resilience-network.html#in-this-lesson-you-will",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "",
    "text": "Understand the relationship between sealevel rise, salt water intrusion, and agricultural productivity in Maryland’s coastal regions\nLearn to work with and analyze multiple types of geospatial data (raster datasets) using Python\nInterpret vegetation health patterns using satellite-derived NDVI measurements\nEvaluate potential future impacts of sea level rise on agricultural land\n\nThis lesson will allow the learner to gain a deper understanding of the followinf concepts - Recognizing the economic importance of agriculture in Maryland - Understanding how sea level rise is impacting coastal farming - Identifying the role of remote sensing in monitoring environmental changes - Connecting local agricultural challenges to broader climate change impacts\nThis module can help to contextualize the impact of saltwater inundation. For this module, we will identify cropland, and then, using the NOAA sea level rise estimations, we can calculate the difference in productivity using NDVI as a measure of vegetation health. A graphical time series allows us to see areas impacted by sea level rise.\nFirst, we can find the county-level statistics of harvestable acreage. We are using the Crop Data Layer (CDL) from the United States Department of Agriculture National Agriculture Statistics Service (USDA NASS)\n\nUse API to call in the CDL dataset to map crop types.\n\nAfter getting familiar with the dataset, we can modify it. Because we are interested in the impact of sea level rise and the effect we can find that data from the National Oceanic and Atmospheric Administration\n\nAccess the Sea level rise (elevation dataset) to identify new areas of potential areas that are at risk of future flooding. Clip to county of interest\nCompare the CDL with the SLR mask and without to identify the NOAA estimated loss of land.\n\nThen using Landsat create a time series for the Normalized Difference Vegetation Index (NDVI) of the masked cropland, derive insights about trends in NDVI.\n\nUse NDVI to create a time series looking back in time at areas that have experienced flooding to visualize the movement from productive farms to moderate quality.\n\nThis all together would allow us to make a predictive analysis for Maryland in the future under the projections of sea level rise. Given the current conditions, subtracting the sea level rise inundated areas.\nThe data story we have derived concerns sea level rise in Maryland and its impact on production levels within the state. This module can help students draw from multiple data sources and derive insights using historical and future viewing data sets.\nWe can prompt the user to think about future impacts outside the direct sea level rise projections, allowing them to include a full picture and finally using that picture to identify economic impacts that action or inaction causes. This begs the question: What can the public do to enact changes rather than putting pressure on farmers to change?"
  },
  {
    "objectID": "m401-nasa-acres-climate-resilience-network.html#footnotes",
    "href": "m401-nasa-acres-climate-resilience-network.html#footnotes",
    "title": "NASA Acres and Climate Resilience Network",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCredit: NASA Acres↩︎\nPhoto courtesy of Jarrod Miller↩︎\nCourtesy of the authors↩︎"
  },
  {
    "objectID": "m401-human-exposure-heat.html",
    "href": "m401-human-exposure-heat.html",
    "title": "Understanding Human Exposure to Heat",
    "section": "",
    "text": "In this bite-size lesson, you will use Google Earth Engine to look at data from Daymet Daily Surface Weather and Climatological Summaries, Social Vulnerability Index Grids, and US Grids to learn how to import, clean, visualize, and analyze temperature and social vulnerability data."
  },
  {
    "objectID": "m401-human-exposure-heat.html#overview",
    "href": "m401-human-exposure-heat.html#overview",
    "title": "Understanding Human Exposure to Heat",
    "section": "",
    "text": "In this bite-size lesson, you will use Google Earth Engine to look at data from Daymet Daily Surface Weather and Climatological Summaries, Social Vulnerability Index Grids, and US Grids to learn how to import, clean, visualize, and analyze temperature and social vulnerability data."
  },
  {
    "objectID": "m401-human-exposure-heat.html#learning-objectives",
    "href": "m401-human-exposure-heat.html#learning-objectives",
    "title": "Understanding Human Exposure to Heat",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this lesson, you should be able to:\n\nSearch for and import data into the Google Earth Engine Code Editor\nSubset data in Google Earth Engine\nUnderstand how to use cloud assets\nVisualize the relationship between temperature change and social vulnerability using scatter plots"
  },
  {
    "objectID": "m401-human-exposure-heat.html#introduction",
    "href": "m401-human-exposure-heat.html#introduction",
    "title": "Understanding Human Exposure to Heat",
    "section": "Introduction",
    "text": "Introduction\n\nWhat is Climate Change?\nClimate change refers to long-term shifts in weather patterns and characteristics, including changes in temperature and precipitation (such as rain and snow) and an increase in extreme weather events like hurricanes, wildfires, and sea-level rise (Romm 2022). The primary cause of climate change is human activity, particularly the burning of fossil fuels like coal, oil, and gas, which release greenhouse gasses into the atmosphere.\n\n\n\n\n\nThe graph above demonstrates the monthly average of carbon dioxide, a driving greenhouse gas in climate change, measured in the last five years at Mauna Loa Observatory. Although the oscillations above can be explained by seasonal variation, there is a steady increase in carbon dioxide concentrations over these five years. Below is a graph demonstrating average carbon dioxide levels over the last 60 years, where increases of over 100 parts per million have been recorded.\n\n\n\n\n\nOther greenhouse gas contributors include methane, nitrous oxides, and fluorinated gasses (Kuok Ho 2022). These gasses are largely generated by industries such as transportation, construction, agriculture, and land-use conversion. For instance, transportation is responsible for 19.2% of global carbon emissions and is expected to double by 2050, significantly raising global temperatures (Abraham et al. 2012). Similarly, agriculture contributes to greenhouse gas emissions through fertilizer and pesticide production, machinery use, diesel consumption, and emissions from crop irrigation (Yin et al. 2024). These emissions pose numerous threats, potentially leading to food insecurity, water scarcity, catastrophic storms, rising sea levels, flooding, melting polar ice, and declining biodiversity.\n\n\n\n\n\nThe figure above shows the release and increase of Greenhouse Gas Emissions dating back to the 1700s. Earth’s current temperature is the warmest it has been in the last 100,000 years, with an average increase of 1.2 degrees Celsius compared to the late 1800s (Nations n.d.). Addressing the primary drivers of climate change, such as transportation emissions, offers promising solutions. Public transportation, electric vehicles, and non-motorized transport could significantly reduce these emissions (Jochem, Rothengatter, and Schade 2016). Public support for climate action is also growing. A 2018 study by the University of Chicago revealed that two-thirds of Americans would back a carbon tax if the proceeds were directed toward environmental restoration (Oreskes 2024). Government action has mirrored this shift in public sentiment. In 2022, President Biden signed the Inflation Reduction Act, marking the largest investment in the economy, energy security, and climate initiatives in U.S. history (Rajagopalan and Landrigan 2023). Recently, President Trump has instituted massive cutbacks to climate change progress and policy, including pulling the United States from the Paris Agreement and pledging to increase fossil fuel production in the country. Experts expect these decisions to hurt climate progress in the United States.\n\n\nHeat and Human Health\nRising global temperatures will also have negative effects on human health. The National Oceanic and Atmospheric Administration (NOAA) has generated the classifications below on the effects of heat on the human body (Service 2024).\n\n\n\n\n\nProlonged exposure and activity in the heat can lead to dangerous heat disorders for humans, and disproportionately impacts vulnerable populations, including children, adults over 65 years old, adults with underlying health conditions, pregnant women, and outdoor workers. The CDC found that in 2023, the warm-season of May through September saw peak heat-related illness emergency visits (Disease Control and (CDC) 2024). As climate change causes longer, hotter, and more frequent extreme heat around the world, we can expect to see more heat-related illnesses."
  },
  {
    "objectID": "m401-human-exposure-heat.html#exploring-the-data",
    "href": "m401-human-exposure-heat.html#exploring-the-data",
    "title": "Understanding Human Exposure to Heat",
    "section": "Exploring the Data",
    "text": "Exploring the Data\n\nDaymet V4: Daily Surface Weather and Climatological Summaries\nDaymet V4 provides gridded estimates of daily weather parameters for Continental North America, Hawaii, and Puerto Rico. It is derived from selected meteorological station data and various supporting data sources. Daymet is provided by NASA ORNL (Oak Ridge National Laboratory) DAAC (Distributed Active Archive Center). The data is available starting in 1980 through 2023 with daily coverage. Each pixel size is 1000 meters (1 kilometer). Daymet provides a number of variables, including total precipitation, daily maximum and minimum 2-meter air temperature, and several other meteorological factors. You can find a full list of the variables on the Earth Engine Data Catalog entry for Daymet V4.\nBecause the analysis we will be doing today will focus on Arizona state, we will be using Daymet V4. However, there are several datasets with global spatial resolution for those who are interested in visualizing and analyzing temperature change in other parts of the world. Try utilizing the Earth Engine Data Catalog search engine for data you are interested in.\n\n\nTIGER: US Census States 2018\nThe United States Census Bureau TIGER dataset contains the 2018 boundaries for the primary governmental divisions of the United States. In addition to the fifty states, the Census Bureau treats the District of Columbia, Puerto Rico, and each of the island areas (American Samoa, the Commonwealth of the Northern Mariana Islands, Guam, and the U.S. Virgin Islands) as the statistical equivalents of States for the purpose of data presentation. Each feature represents a state or state equivalent. Our analysis will focus on Arizona state, but we will learn how to select any state from the TIGER boundaries. This means that once our lesson is complete, you will be able to do the same analysis on the state of your choosing. Try the same analysis on a neighboring state or a different region of the US.\n\n\nU.S. Social Vulnerability Index Grids\nThe U.S. Social Vulnerability Index Grids, Revision 01 data set contains gridded layers for the overall Centers for Disease Control and Prevention (CDC) Social Vulnerability Index (SVI) using four sub-category themes (Socioeconomic, Household Composition & Disability, Minority Status & Language, and Housing Type & Transportation) based on census tract level inputs from 15 variables for the years 2000, 2010, 2014, 2016, 2018, and 2020. SVI values range between 0 and 1 based on their percentile position among all census tracts in the U.S., with 0 representing lowest vulnerability census tracts and 1 representing highest vulnerability census tracts. SEDAC has gridded these vector inputs to create 1 kilometer spatial resolution raster surfaces allowing users to obtain vulnerability metrics for any user-defined area within the U.S. Utilizing inputs from CIESIN’s Gridded Population of the World, Version 4 (GPWv4) Revision 11 data sets, a mask is applied for water, and optionally, for no population. The data are provided in two different projection formats, NAD83 as a U.S. specific standard, and WGS84 as a global standard. The goal of the SVI is to help identify vulnerable communities by ranking them on these inputs across the U.S.\nThe SEDAC Social Vulnerability Index Grids data set rasterizes these census tract-level social vulnerability measures at 1 kilometer spatial resolution to fit the standard grid of CIESIN’s Gridded Population of the World, Version 4 (GPWv4) Revision 11 and U.S. Census Grid families of population products. In addition to the general SVI indicator, gridded layers are provided for four sub-category themes (Socioeconomic, Household Composition & Disability, Minority Status & Language, and Housing Type & Transportation). SEDAC gridded the vector SVI data for each of the five layers for each of the years 2000, 2010, 2014, 2016, 2018, and 2020.\nFor our analysis, we will be using overall SVI rather than selecting from the sub-category themes. Overall SVI considers all the sub-categories rather than breaking them down into individual layers. For longer analyses, it is recommended that you focus on sub-categories that are of most interest to you.\n\n\nU.S. Census GRIDS\nU.S. Census Grids, Demographic and Housing Characteristics File, 2020 contain grids of demographic and socioeconomic data from the 2020 U.S. Census. The data are available for download in GeoTIFF, and Shapefile formats. The grids have a resolution of 15 arc-seconds (0.00415 decimal degrees), or approximately 500 square meters at the equator. The gridded data are derived from census block geography from Census 2020 APIs, and variables on population, households, and housing from Census 2020 Demographic and Housing Characteristics File (DHC). This data set is produced by the Columbia University Center for International Earth Science Information Network (CIESIN) using data provided by the U.S. Census Bureau.\nThe gridded variables are based on census block geography from Census 2020 Demographic and Housing Characteristics File acquired through the U.S. Census APIs, and variables on population, households, and housing from Census 2020 Demographic and Housing Characteristics File (DHC)."
  },
  {
    "objectID": "m401-human-exposure-heat.html#working-with-the-data",
    "href": "m401-human-exposure-heat.html#working-with-the-data",
    "title": "Understanding Human Exposure to Heat",
    "section": "Working with the Data",
    "text": "Working with the Data\nFor this lesson, we will import each dataset and clean the data before importing the next one.\nLaunch the Code Editor ↗\n//Note: In Google Earth Engine, we can use ‘//’ to write notes without having it impact our code. The Code Editor will ignore whatever is written after ‘//’\n\n//Import Daymet dataset for 2023: Daily Surface Weather and Climatological Summaries\nvar daymet_2023 = ee.ImageCollection('NASA/ORNL/DAYMET_V4') //Let’s name the variable 'daymet_2023' to keep track of the dataset we are using\n                  .filter(ee.Filter.date('2023-07-01', '2023-07-30')); //The ee.Filter.date function will help us identify the time series we'd like to use. Once you are comfortable with filtering the date, feel free to change this to what you are interested in looking at.\nvar maximumTemperature_2023 = daymet_2023.select('tmax'); //By selecting ‘tmax’, we are selecting the maximum temperature for the time series we selected\n\n//Import the same dataset in 1980 to compare the temperatures\nvar daymet_1980 = ee.ImageCollection('NASA/ORNL/DAYMET_V4') //Let’s name this variable 'daymet_1980' \n                  .filter(ee.Filter.date('1980-07-01', '1980-07-30')); //Identify the time series we'd like to use again\nvar maximumTemperature_1980 = daymet_1980.select('tmax');\n\n\n//Next, calculate the average maximum temperature for the first time series we selected (2023)\nvar averageMaximumTemperature_2023 = maximumTemperature_2023.mean();\n\n//Do the same for 1980\nvar averageMaximumTemperature_1980 = maximumTemperature_1980.mean();\n\n\n//Create a color palette variable for temperature on a celsius scale using a 0-30 degree range\nvar maximumTemperatureVis = {\n  min: 0.0, //The ‘min’ and ‘max’ will refer to the minimum and maximum values on our scale\n  max: 30.0,\n  palette: ['1621A2', 'white', 'cyan', 'green', 'yellow', 'orange', 'red'], //Select an intuitive color scheme for visualizing temperature\n};\nGreat! Now that we have visualizations of temperature in 1980 and 2023, let’s import our state boundaries for Arizona. We will clip the average maximum temperature for both our points in time to visualize just Arizona.\nLaunch the Code Editor ↗\n//Load Arizona's boundary from TIGER\nvar arizona = ee.FeatureCollection('TIGER/2018/States')\n                .filter(ee.Filter.eq('NAME', 'Arizona')); //Google Earth Engine will recognize the states by their name; feel free to experiment with loading in additional states to see how it works\n\n//Clip the average maximum temperature to Arizona in 2023\nvar clippedAverageTemperature_2023 = averageMaximumTemperature_2023.clip(arizona);\n\n//Do the same for 1980\nvar clippedAverageTemperature_1980 = averageMaximumTemperature_1980.clip(arizona);\n\n//Visualize the clipped average temperature\nMap.setCenter(-99.21, 31.8, 4); //The ‘Map.setCenter’ is a function that will set the initial center and zoom level on the map based on coordinates\n\nMap.addLayer(clippedAverageTemperature_2023, maximumTemperatureVis, 'Average Maximum Temperature (2023)');\n\nMap.addLayer(clippedAverageTemperature_1980, maximumTemperatureVis, 'Average Maximum Temperature (1980)');\nGreat! We’ve subset and cleaned the data so far. Next, we will calculate the temperature difference between 1980 and 2023 to see how it has changed in Arizona.\nLaunch the Code Editor ↗\nvar temperatureDifference = clippedAverageTemperature_2023.subtract(clippedAverageTemperature_1980);\n//Using ‘subtract’ will subtract the pixel values of two images.\n\n//Define visualization parameters for the temperature difference. By creating a variable for this, we can reference it when adding a map layer\n\nvar tempDiffVis = {\n  min: -5.0, \n  max: 5.0, \n  palette: ['blue', 'white', 'red'] //Blue = cooling, white = no change, red = warming\n};\n\n//Visualize the temperature difference by adding the layer to the map\nMap.addLayer(temperatureDifference, tempDiffVis, 'Temperature Difference Between 1980 and 2023');\n\n\n\n\n\nNow we have the temperature change in Arizona between 1980 and 2025! Use the inspector tool to see how different regions have warmed or cooled. By how many degrees has warming occurred in areas that are red on the map? By how many degrees has cooling occurred in areas that are blue on the map?\nLet’s move onto the next part of our analysis and visualize social vulnerability and heat vulnerable ages in Arizona. For this, we will use cloud assets. This allows us to upload our own data into Google Earth Engine. Cloud Assets are stored in Google Cloud Products and can include images, image collections, tables, and folders for analysis in Google Earth Engine. You can read more here.\nFor this analysis, we will need to access three Cloud Assets:\nBy clicking here, you will access the SVI Cloud Asset. By clicking here, you will access the 65 to 79 age group Cloud Asset. By clicking here, you will access the over 80 age group Cloud Asset. Add these to your project and rename the variables ‘svi_overall’, ‘az65_79’, and ‘az_80ov’, respectively. You can do this in the import bar on the top of the Code Editor.\nLaunch the Code Editor ↗\n//Import SVI overall \nvar svi_overall = ee.Image(svi_overall);\n\n//Define visualization parameters\nvar svi_palette = {\n  min: 0,\n  max: 1,\n  palette: ['440154', '3b528b', '21918c', '5ec962', 'fde725'] //This is a more traditional SVI palette, but feel free to change the colors to what is most intuitive for you\n};\n\n//Clip to arizona\nvar sviArizona = svi_overall.clip(arizona);\n\n//Add the SVI layer to the map using the palette we created\nMap.addLayer(sviArizona, svi_palette, 'SVI');\n\n\n\n\n\nWe can now visualize SVI on the map over Arizona! Next, we’ll generate a chart to display average temperature change by SVI.\nLaunch the Code Editor ↗\n//Group SVI into 5 categories\nvar sviQuintiles = sviArizona.expression(\n   \"(b1 &lt; 0.2) ? 0\" +  // SVI &lt; 0.2\n   \": (b1 &lt;= 0.2) ? 0.2\" +  // 0.2 &lt;= SVI &lt;= 0.4\n   \": (b1 &lt;= 0.4) ? 0.4\" +  // 0.4 &lt;= SVI &lt;= 0.6\n   \": (b1 &lt;= 0.6) ? 0.6\" +  // 0.6 &lt;= SVI &lt;= 0.8\n   \": (b1 &lt;= 0.8) ? 0.8\" +  // 0.8 &lt;= SVI &lt;= 1\n   \": 1\", {  // SVI &gt; 0.8\n    'b1': sviArizona\n  }\n).rename('SVI_Quintile');\n\n//Compute the mean temperature change for each SVI quintile\nvar stats = temperatureDifference.addBands(sviQuintiles)\n  .reduceRegion({  //Reduce region allows us to summarize values in a geographic region; in this case, we will use mean\n    reducer: ee.Reducer.mean().group({\n      groupField: 1,\n      groupName: 'SVI_Quintile'\n    }),\n    geometry: arizona,\n    scale: 500,\n    maxPixels: 1e13\n  });\n\n//Extract the 'groups' list: this will extract a list of grouped statistics from the reduceRegion function\nvar groups = ee.List(stats.get('groups'));\n\n//Convert groups into proper dictionaries and extract SVI and average temperature change\n//This converts grouped statistics into two lists (one for SVI and one for average temperature change)\nvar sviValues = groups.map(function(item) {\n  return ee.Dictionary(item).get('SVI_Quintile');\n});\nvar tempChanges = groups.map(function(item) {\n  return ee.Dictionary(item).get('mean');\n});\n\n//Create the chart using ui.Chart.array.values(); we will make stylistic choices here as well\nvar SVIchart = ui.Chart.array.values({\n  array: tempChanges,\n  axis: 0,\n  xLabels: sviValues\n})\n.setChartType('LineChart')\n.setOptions({\n  title: 'Average Temperature Change by SVI',\n  hAxis: {\n    title: 'Social Vulnerability Index  (0 = Lowest, 1 = Highest)',\n    viewWindow: {min: 0, max: 1}, // Ensure the scale is from 0 to 1\n    ticks: [0, 0.2, 0.4, 0.6, 0.8, 1] // Define tick marks for clarity\n  },\n  vAxis: {title: 'Average Temperature Change (°C)'},\n  lineWidth: 3,\n  pointSize: 5,\n  colors: ['red']\n});\n\n//Display the chart\nprint(SVIchart);\n\n\n\n\n\nWe now have a visual chart showing how temperature has changed based on social vulnerability groups. What can you notice about more and less vulnerable populations and temperature change?\nNow that we have visualized social vulnerability in Arizona, let’s use US GRIDS to look at a specific population vulnerable to heat: those over 65. To do this, we’ll use US GRIDS 65-79 and over 80 years old age groups.\nLaunch the Code Editor ↗\n//Create a 65+ age group. For this, we’ll use the .add function\nvar az_65plus = az65_79.add(az_80ov); //Note: you cannot create variables in GEE that start with numbers. For this reason, we are naming the variable az_65plus rather than 65plus_az\n\n//Define temperature change bins\nvar tempBins = [-1, 0, 1, 2, 3, 4]; //Bins are used to group data into intervals; in this case, we are grouping temperature change into bins for our analysis\n\n//Classify temperature difference into bins\nvar tempClasses = temperatureDifference.expression(\n  \"(b1 &lt; 0) ? -1\" +   // Less than 0°C\n  \": (b1 &lt; 1) ? 0\" +  // 0 to 1°C\n  \": (b1 &lt; 2) ? 1\" +  // 1 to 2°C\n  \": (b1 &lt; 3) ? 2\" +  // 2 to 3°C\n  \": (b1 &lt; 4) ? 3\" +  // 3 to 4°C\n  \": 4\",               // Above 4°C\n  {'b1': temperatureDifference}\n).rename('TempBin');\n\n//Sum the 65+ population within each temperature bin to find the total in each group\nvar popExposure = az_65plus.addBands(tempClasses)\n  .reduceRegion({\n    reducer: ee.Reducer.sum().group({\n      groupField: 1,\n      groupName: 'TempBin'\n    }),\n    geometry: arizona,\n    scale: 500,\n    maxPixels: 1e13\n  });\n\n//Extract the groups list\nvar groups = ee.List(popExposure.get('groups'));\n\n//Extract temperature bins and population sums\nvar tempLabels = groups.map(function(item) {\n  return ee.Dictionary(item).get('TempBin');\n});\nvar popValues = groups.map(function(item) {\n  return ee.Dictionary(item).get('sum');\n});\n\n//Create a histogram of exposure\nvar exposureChart = ui.Chart.array.values({\n  array: popValues,\n  axis: 0,\n  xLabels: tempLabels\n})\n.setChartType('ColumnChart')\n.setOptions({\n  title: '65+ Population Exposure to Temperature Change',\n  hAxis: {\n    title: 'Temperature Change (°C)',\n    viewWindow: {\n      min: -1,  // Set the minimum value for the x-axis to -1\n      max: 4    // Set the maximum value for the x-axis to 4\n    }\n  },\n  vAxis: {title: '65+ Population Count'},\n  legend: {position: 'none'},\n  colors: ['#ff5733']\n});\n\n//Print the chart\nprint(exposureChart);\n\n\n\n\n\nWe’ve now created a graph that shows us the count of how many individuals over the age of 65 are in areas that are experiencing temperature change in Arizona. How might this change as climate change continues?\nCongratulations! We were able to download, import, and explore Daymet, TIGER, SVI, and US GRIDS data to see how the state of Arizona has been impacted by temperature change and how vulnerable populations have been affected. Try the lesson again and look at different states for temperature change and SVI. You should now be able to:\n\nImport data into the Google Earth Engine Code Editor\nSubset data in the Code Editor and create bins of data\nUse cloud assets\nVisualize the relationship between temperature change and social vulnerability using scatter plots"
  },
  {
    "objectID": "m403-flash-drought-ag.html",
    "href": "m403-flash-drought-ag.html",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "",
    "text": "Flash drought has emerged as a critical research priority for NOAA, NIDIS (National Integrated Drought Information System), and the broader meteorological community. Unlike conventional droughts that develop over months or years, flash droughts are characterized by their unusually rapid intensification over periods of days to weeks, often catching stakeholders unprepared and resulting in disproportionate impacts.\nThe National Integrated Drought Information System (NIDIS) has specifically identified flash drought as a key research priority in their strategic plans, recognizing significant gaps in our ability to monitor, predict, and communicate these events. According to NIDIS, flash droughts pose unique challenges due to:\n\nTheir rapid development that outpaces traditional drought monitoring cycles\nCurrent monitoring systems not optimized for rapid-onset conditions\nLimited subseasonal prediction capabilities for these events\nDifficulty in effectively communicating risk when conditions deteriorate rapidly\n\nNOAA has emphasized developing improved early warning systems for flash drought, particularly in agriculturally sensitive regions where economic impacts can be substantial. The importance of multi-indicator approaches has been highlighted as essential for capturing the complex and rapid evolution of these events."
  },
  {
    "objectID": "m403-flash-drought-ag.html#research-priority-context",
    "href": "m403-flash-drought-ag.html#research-priority-context",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "",
    "text": "Flash drought has emerged as a critical research priority for NOAA, NIDIS (National Integrated Drought Information System), and the broader meteorological community. Unlike conventional droughts that develop over months or years, flash droughts are characterized by their unusually rapid intensification over periods of days to weeks, often catching stakeholders unprepared and resulting in disproportionate impacts.\nThe National Integrated Drought Information System (NIDIS) has specifically identified flash drought as a key research priority in their strategic plans, recognizing significant gaps in our ability to monitor, predict, and communicate these events. According to NIDIS, flash droughts pose unique challenges due to:\n\nTheir rapid development that outpaces traditional drought monitoring cycles\nCurrent monitoring systems not optimized for rapid-onset conditions\nLimited subseasonal prediction capabilities for these events\nDifficulty in effectively communicating risk when conditions deteriorate rapidly\n\nNOAA has emphasized developing improved early warning systems for flash drought, particularly in agriculturally sensitive regions where economic impacts can be substantial. The importance of multi-indicator approaches has been highlighted as essential for capturing the complex and rapid evolution of these events."
  },
  {
    "objectID": "m403-flash-drought-ag.html#overview",
    "href": "m403-flash-drought-ag.html#overview",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Overview",
    "text": "Overview\nThis educational workflow analyzes the 2022 flash drought events in the south-central United States (Oklahoma, Arkansas, and Missouri) that severely impacted agricultural systems, particularly pasturelands and livestock operations. Students will learn to work with multiple drought indicators to understand rapid drought intensification and its agricultural impacts. The workflow demonstrates cutting-edge approaches aligning with NIDIS and NOAA research priorities for improving flash drought monitoring, understanding, and impact assessment."
  },
  {
    "objectID": "m403-flash-drought-ag.html#use-case",
    "href": "m403-flash-drought-ag.html#use-case",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Use Case",
    "text": "Use Case\nThe 2022 south-central US experienced a rare phenomenon of two consecutive flash drought events (June-July and August-September) separated by a recovery period. This led to severe agricultural impacts including: - Rapid decline in pastureland conditions - Forced livestock selloffs - 12% reduction in Oklahoma’s cattle population - Hydrological impacts affecting the Mississippi River\nThis provides an excellent case study for multi-indicator flash drought analysis with clear agricultural relevance."
  },
  {
    "objectID": "m403-flash-drought-ag.html#learning-objectives",
    "href": "m403-flash-drought-ag.html#learning-objectives",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nProcess and analyze multiple flash drought indicators\nExamine temporal relationships between different indicators\nExplore spatial patterns of flash drought development\nConnect meteorological conditions to agricultural impacts\nEvaluate the unique characteristics of rapid drought intensification\nUnderstand why flash drought research is an emerging priority in drought science\nDevelop skills relevant to NIDIS and NOAA research initiatives in flash drought\nRecognize the distinctive monitoring challenges flash droughts present compared to conventional droughts"
  },
  {
    "objectID": "m403-flash-drought-ag.html#dataset-description",
    "href": "m403-flash-drought-ag.html#dataset-description",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Dataset Description",
    "text": "Dataset Description\n\nSPORT-LIS soil moisture: Daily 4km resolution root zone soil moisture (primary dataset)\nGOES-LST: Land surface temperature at 2km resolution\nRTMA air temperature: 2.5km resolution air temperature analysis\nOpenET: Ensemble evapotranspiration estimates\nMODIS NDVI: 16-day vegetation health indicators\nUSDA pasture conditions: Weekly agricultural impact assessments"
  },
  {
    "objectID": "m403-flash-drought-ag.html#workflow-outline",
    "href": "m403-flash-drought-ag.html#workflow-outline",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Workflow Outline",
    "text": "Workflow Outline\n\nPart 1: Data Acquisition and Preparation\n\nDefine study area (Oklahoma, Arkansas, Missouri)\nSet study time period (May-October 2022)\nDownload and import datasets\nStandardize spatial extent and resolution\nCreate time series of domain-averaged values\n\n\n\nPart 2: Flash Drought Identification and Analysis\n\nCalculate soil moisture percentiles and anomalies\nIdentify rapid intensification periods\nExamine temperature patterns during flash drought development\nAnalyze evapotranspiration response\nQuantify vegetation impacts through NDVI changes\n\n\n\nPart 3: Multi-Indicator Relationship Analysis\n\nCreate time series plots of multiple indicators\nExamine lead/lag relationships between indicators\nIdentify key thresholds for agricultural impacts\nCompare first and second flash drought events\nAnalyze recovery period characteristics\n\n\n\nPart 4: Spatial Analysis\n\nCreate maps of drought intensification rates\nCompare spatial patterns across indicators\nIdentify agricultural hotspots most severely impacted\nExamine differences in land cover response\n\n\n\nPart 5: Agricultural Impact Assessment\n\nAnalyze pasture condition reports\nCorrelate soil moisture with pasture conditions\nExamine temporal lags between drought and impacts\nEvaluate economic implications where data available"
  },
  {
    "objectID": "m403-flash-drought-ag.html#technical-approach",
    "href": "m403-flash-drought-ag.html#technical-approach",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Technical Approach",
    "text": "Technical Approach\nThis workflow will use line-by-line scripted code rather than functions or iterations, allowing students to inspect environment objects at each step. The focus will be on:\n\nClear, well-commented code for each data processing step\nStraightforward visualizations showing relationships\nFull state-level analysis rather than smaller subregions\nStep-by-step building of analytical skills\nEmphasis on agricultural interpretation of results\n\nThe workflow adopts methodologies aligned with NIDIS Flash Drought initiatives, including: - Multi-indicator monitoring approaches highlighted in NIDIS workshops - Integration of both meteorological and agricultural metrics - Analysis timescales appropriate for capturing rapid intensification - Emphasis on impact-focused drought assessment - Techniques that could contribute to improved early warning systems"
  },
  {
    "objectID": "m403-flash-drought-ag.html#expected-outcomes",
    "href": "m403-flash-drought-ag.html#expected-outcomes",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Expected Outcomes",
    "text": "Expected Outcomes\nStudents will develop a comprehensive understanding of: 1. How flash droughts differ from conventional droughts 2. Why multi-indicator approaches are valuable 3. The sequence of physical processes during flash drought development 4. How agricultural impacts manifest during rapid drought intensification 5. The importance of temporal resolution in drought monitoring 6. Current limitations in flash drought monitoring and prediction 7. The role of interdisciplinary approaches in drought science 8. How this research aligns with national drought resilience initiatives"
  },
  {
    "objectID": "m403-flash-drought-ag.html#extensions-if-time-allows",
    "href": "m403-flash-drought-ag.html#extensions-if-time-allows",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Extensions (If Time Allows)",
    "text": "Extensions (If Time Allows)\n\nCompare with a conventional drought event\nExplore teleconnections that may have contributed to these events\nAnalyze heatwave-drought feedbacks\nExamine predictability of these events using S2S models\nDevelop simple impact forecasting model\nCreate a flash drought early warning framework\nAnalyze flash drought economic impact estimation approaches\nExplore connections to NIDIS Drought Early Warning Systems"
  },
  {
    "objectID": "m403-flash-drought-ag.html#relevance-to-national-initiatives",
    "href": "m403-flash-drought-ag.html#relevance-to-national-initiatives",
    "title": "Flash Drought Multi-Indicator Analysis: Educational R Workflow",
    "section": "Relevance to National Initiatives",
    "text": "Relevance to National Initiatives\nThis educational workflow directly supports several national drought science priorities:\n\nNIDIS Flash Drought Working Group objectives - Enhancing understanding of flash drought dynamics and improving monitoring capabilities\nNOAA Subseasonal-to-Seasonal (S2S) Prediction Initiative - Supporting improved prediction of extreme events including flash droughts\nUSDA Climate Hubs - Providing practical knowledge for agricultural adaptation to rapid-onset climate extremes\nNational Climate Assessment - Contributing to understanding of compound climate extremes and their sectoral impacts\n\nThe analytical approaches demonstrated align with recommendations from the NIDIS Flash Drought Workshop series (2017-2022) which emphasized the need for multi-scale, multi-indicator monitoring systems that capture rapid changes in the climate-agriculture nexus."
  }
]